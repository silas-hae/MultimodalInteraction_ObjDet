{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify Object Positions in Images - YOLO vs VLM "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils \n",
    "Taken from \n",
    "https://colab.research.google.com/drive/1eDvf_Ky9jLOZFShgHrm4GI-wkAaQnue6?usp=sharing#scrollTo=wizbxA1lm-Tj\n",
    "https://colab.research.google.com/github/google-gemini/cookbook/blob/main/examples/Object_detection.ipynb#scrollTo=245bc92a470f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Plotting Utils\n",
    "import json\n",
    "import random\n",
    "import io\n",
    "from PIL import Image, ImageDraw\n",
    "from PIL import ImageColor\n",
    "\n",
    "additional_colors = [colorname for (colorname, colorcode) in ImageColor.colormap.items()]\n",
    "\n",
    "def plot_bounding_boxes(im, noun_phrases_and_positions):\n",
    "    \"\"\"\n",
    "    Plots bounding boxes on an image with markers for each noun phrase, using PIL, normalized coordinates, and different colors.\n",
    "\n",
    "    Args:\n",
    "        img_path: The path to the image file.\n",
    "        noun_phrases_and_positions: A list of tuples containing the noun phrases\n",
    "         and their positions in normalized [y1 x1 y2 x2] format.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image\n",
    "    img = im\n",
    "    width, height = img.size\n",
    "    print(img.size)\n",
    "    # Create a drawing object\n",
    "    draw = ImageDraw.Draw(img)\n",
    "\n",
    "    # Define a list of colors\n",
    "    colors = [\n",
    "    'red',\n",
    "    'green',\n",
    "    'blue',\n",
    "    'yellow',\n",
    "    'orange',\n",
    "    'pink',\n",
    "    'purple',\n",
    "    'brown',\n",
    "    'gray',\n",
    "    'beige',\n",
    "    'turquoise',\n",
    "    'cyan',\n",
    "    'magenta',\n",
    "    'lime',\n",
    "    'navy',\n",
    "    'maroon',\n",
    "    'teal',\n",
    "    'olive',\n",
    "    'coral',\n",
    "    'lavender',\n",
    "    'violet',\n",
    "    'gold',\n",
    "    'silver',\n",
    "    ] + additional_colors\n",
    "\n",
    "    # Iterate over the noun phrases and their positions\n",
    "    for i, (noun_phrase, (y1, x1, y2, x2)) in enumerate(\n",
    "        noun_phrases_and_positions):\n",
    "        # Select a color from the list\n",
    "        color = colors[i % len(colors)]\n",
    "\n",
    "        # Convert normalized coordinates to absolute coordinates\n",
    "        abs_x1 = int(x1/1000 * width)\n",
    "        abs_y1 = int(y1/1000 * height)\n",
    "        abs_x2 = int(x2/1000 * width)\n",
    "        abs_y2 = int(y2/1000 * height)\n",
    "\n",
    "        # Draw the bounding box\n",
    "        draw.rectangle(\n",
    "            ((abs_x1, abs_y1), (abs_x2, abs_y2)), outline=color, width=4\n",
    "        )\n",
    "\n",
    "        # Draw the text\n",
    "        draw.text((abs_x1 + 8, abs_y1 + 6), noun_phrase, fill=color)\n",
    "\n",
    "    # Display the image\n",
    "    img.show()\n",
    "\n",
    "# @title Parsing utils\n",
    "def parse_list_boxes(text):\n",
    "  result = []\n",
    "  for line in text.strip().splitlines():\n",
    "    # Extract the numbers from the line, remove brackets and split by comma\n",
    "    try:\n",
    "      numbers = line.split('[')[1].split(']')[0].split(',')\n",
    "    except:\n",
    "      numbers =  line.split('- ')[1].split(',')\n",
    "\n",
    "    # Convert the numbers to integers and append to the result\n",
    "    result.append([int(num.strip()) for num in numbers])\n",
    "\n",
    "  return result\n",
    "\n",
    "def parse_list_boxes_with_label(text):\n",
    "  text = text.split(\"```\\n\")[0]\n",
    "  return json.loads(text.strip(\"```\").strip(\"python\").strip(\"json\").replace(\"'\", '\"').replace('\\n', '').replace(',}', '}'))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv  \n",
    "import os\n",
    "import base64\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "  with open(image_path, \"rb\") as image_file:\n",
    "    return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "#openAIclient = openai.OpenAI(api_key=os.environ.get(\"OPENAI_API_KEY\", \"<your OpenAI API key if not set as env var>\"))\n",
    "openAIclient = openai.OpenAI(api_key= os.getenv(\"OPENAI_API_KEY\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "TEXTMODEL = \"gpt-4o-mini\" \n",
    "IMGMODEL= \"gpt-4o-mini\" \n",
    "\n",
    "# Path to your image\n",
    "img = \"images/table_scene.jpeg\" # Laden des Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content='The image depicts a cozy, well-lit table setting. On the table, there is an open book, a\n",
      "pair of glasses, a smartphone, and a mug. There are also a few stacked books, a small succulent plant in a pot, and a\n",
      "larger potted plant in the background. Additionally, there are a couple of decorative items, including a small compass,\n",
      "creating a warm and inviting atmosphere.', role='assistant', function_call=None, tool_calls=None, refusal=None)\n"
     ]
    }
   ],
   "source": [
    "#basic call to gpt4 with prompt and image\n",
    "\n",
    "completion = openAIclient.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": [\n",
    "                {\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "                {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": {\n",
    "                        \"url\": f\"data:image/jpeg;base64,{encode_image(img)}\", # Pfad zu Image\n",
    "                        #\"detail\": \"low\"\n",
    "                    }\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "# Wrap the text to a specified width\n",
    "\n",
    "response = str(completion.choices[0].message)\n",
    "print(textwrap.fill(response, width=120))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
